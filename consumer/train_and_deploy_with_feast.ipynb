{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Deploy a model using a Feature Store\n",
        "\n",
        "In this notebook we show how to:\n",
        "\n",
        "1. access a feature store registry that has been published to blob\n",
        "1. discover features in the feature store\n",
        "1. train a model using the offline store (using the feast function `get_historical_features()`)\n",
        "1. use the feast `materialize()` function to push features from the offline store to an online store (redis)\n",
        "1. Deploy the model to an Azure ML endpoint where the features are consumed from the online store (feast function `get_online_features()`)\n",
        "\n",
        "## Set the registry connection string\n",
        "Feast gets the credentials to the blob location containing the feast registry file using the `FEAST_AZ_STORAGE_CONNECTION_STRING` environment variable. \n",
        "\n",
        "__NOTE: you will need to set the connection string as a secret first. This is a one-time operation__"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "#keyvault.set_secret('FEAST-REGISTRY-CONN-STRING', '<CONNECTION_STRING>')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "# this is the blob connection string (the blob location contains the registry.db file)\n",
        "os.environ['FEAST_AZ_STORAGE_CONNECTION_STRING']=keyvault.get_secret('FEAST-REGISTRY-CONN-STRING')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Feature store\n",
        "\n",
        "Below we create a Feast repository config, which accesses the registry.db file and also provides the credentials to the offline and online storage.\n",
        "\n",
        "__NOTE: You will need to provide the registry location on your blob storage__"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "from feast import FeatureStore, RepoConfig\n",
        "from feast.repo_config import SqlServerOfflineStoreConfig, RedisOnlineStoreConfig\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "# update this to your location\n",
        "FEAST_REGISTRY_BLOB = \"az://<CONTAINER_NAME>/<PATH>/registry.db\" \n",
        "\n",
        "connection_string = keyvault.get_secret('FEAST-SQL-CONN')\n",
        "redis_endpoint = keyvault.get_secret('FEAST-REDIS-CONN')\n",
        "orders_table = \"orders\"\n",
        "driver_hourly_table = \"driver_hourly\"\n",
        "customer_profile_table = \"customer_profile\"\n",
        "\n",
        "repo_cfg = RepoConfig(\n",
        "        project = \"production\",\n",
        "        provider = \"local\",\n",
        "        registry = FEAST_REGISTRY_BLOB,\n",
        "        offline_store = SqlServerOfflineStoreConfig(connection_string=connection_string),\n",
        "        online_store = RedisOnlineStoreConfig(connection_string=redis_endpoint)\n",
        "    )\n",
        "\n",
        "store = FeatureStore(config=repo_cfg)\n"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627130565121
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List the feature views\n",
        "\n",
        "Below we you see your feature views"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "store.list_feature_views()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627130571909
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load features into a pandas dataframe\n",
        "\n",
        "Below we load the features from the feature store into a pandas data frame"
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627130724228
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sql_job = store.get_historical_features(\n",
        "    entity_df=\"SELECT * FROM orders\",\n",
        "    feature_refs=[\n",
        "        \"driver_stats:conv_rate\",\n",
        "        \"driver_stats:acc_rate\",\n",
        "        \"driver_stats:avg_daily_trips\",\n",
        "        \"customer_profile:current_balance\",\n",
        "        \"customer_profile:avg_passenger_count\",\n",
        "        \"customer_profile:lifetime_trip_count\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "training_df = sql_job.to_df()\n",
        "training_df.head()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626933777036
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get only required features and drop NANs"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = training_df[['order_is_success', \n",
        "    'driver_stats__conv_rate', \n",
        "    'driver_stats__acc_rate',\n",
        "    'driver_stats__avg_daily_trips',\n",
        "    'customer_profile__current_balance',\n",
        "    'customer_profile__avg_passenger_count',\n",
        "    'customer_profile__lifetime_trip_count']].dropna()\n",
        "x.head()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626933796908
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model and capture metrics with MLFlow\n",
        "\n",
        "Below we train a model using the features from the feature store. Note that we also log the feature registry with the model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import mlflow\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# connect to your workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# create experiment and start logging to a new run in the experiment\n",
        "experiment_name = \"order_model\"\n",
        "\n",
        "# set up MLflow to track the metrics\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "training_df = training_df.dropna()\n",
        "X = training_df[['driver_stats__conv_rate', 'driver_stats__acc_rate', 'driver_stats__avg_daily_trips', \n",
        "        'customer_profile__current_balance', 'customer_profile__avg_passenger_count','customer_profile__lifetime_trip_count' ]].dropna()\n",
        "y = training_df['order_is_success']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "clf = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "# train the model\n",
        "with mlflow.start_run() as run:\n",
        "    clf.fit(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare for deployment\n",
        "\n",
        "### Register model and the feature registry "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# register the model\n",
        "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "model = mlflow.register_model(model_uri, \"order_model\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `materialize()` data into the online store (redis)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=7)\n",
        "store.materialize(start_date=start_date, end_date=end_date)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "keyvault = ws.get_default_keyvault()\n",
        "\n",
        "# create deployment config i.e. compute resources\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=1,\n",
        "    description=\"orders service using feast\",\n",
        ")\n",
        "\n",
        "# get registered environment\n",
        "env = Environment.from_conda_specification(\"feast-env\", \"environment.yml\")\n",
        "env.python.conda_dependencies.add_pip_package(\"azureml-defaults\")\n",
        "\n",
        "# again ensure that the scoring environment has access to the registry file\n",
        "env.environment_variables = {\n",
        "    \"FEAST_HIST_CONN\": connection_string,\n",
        "    \"FEAST_REDIS_CONN\": redis_endpoint,\n",
        "    \"FEAST_AZ_STORAGE_CONNECTION_STRING\": os.environ['FEAST_AZ_STORAGE_CONNECTION_STRING'],\n",
        "    \"FEAST_REGISTRY_BLOB\": FEAST_REGISTRY_BLOB\n",
        "}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import uuid\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# get the registered model\n",
        "model = Model(ws, \"order_model\")\n",
        "\n",
        "# create an inference config i.e. the scoring script and environment\n",
        "inference_config = InferenceConfig(\n",
        "    entry_script=\"score.py\", \n",
        "    environment=env, \n",
        "    source_directory=\"src\"\n",
        ")\n",
        "\n",
        "# deploy the service\n",
        "service_name = \"orders-service\" + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# send raw HTTP request to test the web service.\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "# send a random row from the test set to score\n",
        "random_index = np.random.randint(0, len(X_test) - 1)\n",
        "input_data = '{\"driver\":1423, \"customer_id\":50999}'\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(\"POST to url\", service.scoring_uri)\n",
        "print(\"prediction:\", resp.text)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('feast-test': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "newenv"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "interpreter": {
      "hash": "613d966a601f3cb09e011da323334ad47ef40156c92ff5801f125852831662b0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}